import os
import json
import boto3
from aiogram import Bot, Dispatcher, types
from aiogram.contrib.middlewares.logging import LoggingMiddleware
from aiogram.utils import executor

# Настройка бота
bot = Bot(token=os.getenv("TELEGRAM_BOT_TOKEN"))
dp = Dispatcher(bot)
dp.middleware.setup(LoggingMiddleware())

# Настройка AWS
sqs = boto3.client("sqs", region_name="us-east-1")
s3 = boto3.client("s3", region_name="us-east-1")

# Конфигурация AWS-ресурсов
QUEUE_URL = "https://sqs.us-east-1.amazonaws.com/123456789012/pdf-generation-queue"  # Замените на ваш URL
S3_BUCKET = "my-telegram-pdf-bucket"  # Замените на ваш бакет

resource "aws_lambda_function" "pdf_generator" {
  function_name = "pdf-generator-lambda"
  role          = aws_iam_role.lambda_exec_role.arn
  runtime       = "python3.9"
  handler       = "lambda_function.lambda_handler"
  filename      = "lambda_function.zip"  # Архив с кодом (см. ниже)
  timeout       = 30

  environment {
    variables = {
      S3_BUCKET = aws_s3_bucket.pdf_bucket.id
    }
  }
}

resource "aws_lambda_event_source_mapping" "sqs_trigger" {
  event_source_arn = aws_sqs_queue.pdf_generation_queue.arn
  function_name    = aws_lambda_function.pdf_generator.arn
  batch_size       = 1
}

import boto3
from fpdf import FPDF  # pip install fpdf2
import json
import os

s3 = boto3.client("s3")
S3_BUCKET = os.getenv("S3_BUCKET")

def generate_pdf(content, filename):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.multi_cell(0, 10, txt=content)
    pdf.output(filename)
    return filename

def lambda_handler(event, context):
    for record in event["Records"]:
        body = json.loads(record["body"])
        user_id = body["user_id"]
        text = body["text"]
        
        pdf_filename = f"/tmp/{user_id}_document.pdf"
        generate_pdf(text, pdf_filename)
        
        s3_key = f"pdfs/{user_id}.pdf"
        s3.upload_file(pdf_filename, S3_BUCKET, s3_key)
        
    return {"statusCode": 200}

resource "aws_s3_bucket" "pdf_bucket" {
  bucket = "my-telegram-pdf-bucket"  # Укажите уникальное имя
  acl    = "private"
}

resource "aws_s3_bucket_versioning" "pdf_bucket_versioning" {
  bucket = aws_s3_bucket.pdf_bucket.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_iam_role" "lambda_exec_role" {
  name = "lambda-pdf-generator-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17",
    Statement = [{
      Action = "sts:AssumeRole",
      Effect = "Allow",
      Principal = {
        Service = "lambda.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_policy" "lambda_s3_sqs_policy" {
  name = "lambda-s3-sqs-policy"

  policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Action = [
          "sqs:ReceiveMessage",
          "sqs:DeleteMessage",
          "sqs:GetQueueAttributes"
        ],
        Resource = aws_sqs_queue.pdf_generation_queue.arn
      },
      {
        Effect = "Allow",
        Action = [
          "s3:PutObject",
          "s3:GetObject"
        ],
        Resource = "${aws_s3_bucket.pdf_bucket.arn}/*"
      },
      {
        Effect = "Allow",
        Action = [
          "logs:CreateLogGroup",
          "logs:CreateLogStream",
          "logs:PutLogEvents"
        ],
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "lambda_policy_attach" {
  role       = aws_iam_role.lambda_exec_role.name
  policy_arn = aws_iam_policy.lambda_s3_sqs_policy.arn
}

resource "aws_sqs_queue" "example_queue" {
  name                      = "example-queue.fifo"  # Для FIFO очереди добавьте .fifo
  delay_seconds             = 90                    # Задержка доставки сообщений (0-900)
  max_message_size          = 262144                # Макс. размер сообщения (262144 байт = 256 KB)
  message_retention_seconds = 345600                # Хранение сообщений (4 дня)
  receive_wait_time_seconds = 10                    # Долгий опрос (0-20)
  visibility_timeout_seconds = 30       

container_definitions = jsonencode([
    {
      name      = "run-migrations"
      image     = "890742572904.dkr.ecr.eu-central-1.amazonaws.com/devops-bot:latest"
      essential = false
      memory    = 256
      command   = ["domigrations"]
      environment = [{
        name  = "POSTGRES_URL"
        value = "${var.db_endpoint}"
      }]

      logConfiguration = {
        logDrive = "awslogs"
        options = {
          awslogs-group         = aws_cloudwatch_log_group.ecs_logs.name
          awslogs-region        = "eu-central-1"
          awslogs-stream-prefix = "ecs"
        }
      }

    },

Error: creating ECS Task Definition (example-task): operation error ECS: RegisterTaskDefinition, 1 validation error(s) found.
│ - missing required field, RegisterTaskDefinitionInput.ContainerDefinitions[0].LogConfiguration.LogDriver.
│ 
│ 
│   with module.ecs_cluster.aws_ecs_task_definition.ecs_task,
│   on ../modules/ecs_service_atl/main.tf line 36, in resource "aws_ecs_task_definition" "ecs_task":
│   36: resource "aws_ecs_task_definition" "ecs_task" {


Error: creating ECS Task Definition (example-task): operation error ECS: RegisterTaskDefinition, https response error StatusCode: 400, RequestID: 573ee6be-6b1b-4bea-a4a2-09993d0eac27, ClientException: Invalid setting for container 'run-migrations'. At least one of 'memory' or 'memoryReservation' must be specified.
│ 
│   with module.ecs_cluster.aws_ecs_task_definition.ecs_task,
│   on ../modules/ecs_service_atl/main.tf line 31, in resource "aws_ecs_task_definition" "ecs_task":
│   31: resource "aws_ecs_task_definition" "ecs_task" {
│ 


Error: creating RDS DB Instance (terraform-20250416155251204200000002): operation error RDS: CreateDBInstance, https response error StatusCode: 400, RequestID: c56f1d9d-d2f3-4437-a775-933cb046c68a, api error InvalidParameterValue: Invalid DB engine
│ 
│   with module.newversatl.aws_db_instance.test_db,
│   on ../modules/newversatl/main.tf line 121, in resource "aws_db_instance" "test_db":
│  121: resource "aws_db_instance" "test_db" {


Error: creating EC2 Launch Template (test-launch-template): operation error EC2: CreateLaunchTemplate, https response error StatusCode: 400, RequestID: 931fd454-9e50-41f6-9263-eb14a9dee523, api error InvalidUserData.Malformed: Invalid BASE64 encoding of user data.
│ 
│   with module.ecs_cluster.aws_launch_template.ecs_lt,
│   on ../modules/ecs_service_atl/main.tf line 5, in resource "aws_launch_template" "ecs_lt":
│    5: resource "aws_launch_template" "ecs_lt" {
│ 
╵
╷
│ Error: creating ELBv2 application Load Balancer (atllb): operation error Elastic Load Balancing v2: CreateLoadBalancer, https response error StatusCode: 400, RequestID: 77deac47-f776-473b-8c06-28b05a16514f, api error ValidationError: At least two subnets in two different Availability Zones must be specified
│ 
│   with module.newversatl.aws_lb.atllb["atllb"],
│   on ../modules/newversatl/main.tf line 78, in resource "aws_lb" "atllb":
│   78: resource "aws_lb" "atllb" {
│ 
╵
╷
│ Error: creating RDS DB Instance (terraform-20250416153917577000000001): operation error RDS: CreateDBInstance, https response error StatusCode: 400, RequestID: 47d045f8-2b82-4bf5-af06-5d97b75f64b1, InvalidSubnet: No default subnet detected in VPC. Please contact AWS Support to recreate default Subnets.
│ 
│   with module.newversatl.aws_db_instance.test_db,
│   on ../modules/newversatl/main.tf line 116, in resource "aws_db_instance" "test_db":
│  116: resource "aws_db_instance" "test_db" {


Planning failed. Terraform encountered an error while generating this plan.

╷
│ Error: Cycle: module.newversatl.aws_security_group.this["secgrouplb"], module.newversatl.aws_security_group.this["secgroupinstance"], module.newversatl.aws_security_group.this["secgroupdb"]


updating Security Group (sg-0b3669ea628af5c31) ingress rules: authorizing Security Group (ingress) rules: operation error EC2: AuthorizeSecurityGroupIngress, https response error StatusCode: 400, RequestID: 3b487961-a3b6-4833-86fd-d357833aa497, api error InvalidGroupId.Malformed: Invalid id: "secgrouplb" (expecting "sg-...")
│ 
│   with module.newversatl.aws_security_group.this["secgroupinstance"],
│   on ../modules/newversatl/main.tf line 41, in resource "aws_security_group" "this":
│   41: resource "aws_security_group" "this" {


# Используем официальный образ Python 3.10
FROM python:3.10-slim

# Устанавливаем зависимости для Postgres и Redis
RUN apt-get update && apt-get install -y \
    gcc \
    python3-dev \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Рабочая директория
WORKDIR /app

# Копируем зависимости и устанавливаем их
COPY pyproject.toml poetry.lock* /app/
RUN pip install --upgrade pip && \
    pip install poetry && \
    poetry config virtualenvs.create false && \
    poetry install --no-dev --no-root

# Копируем весь проект
COPY . .

# Команда для запуска бота (замените `main:app` на ваш скрипт)
CMD ["poetry", "run", "python", "-m", "your_bot_module.main"]

Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

Traceback (most recent call last):
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3298, in raw_connection
    return self.pool.connect()
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 308, in _do_get
    return self._create_connection()
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)


# curl -v http://app-backend:8000
* Host app-backend:8000 was resolved.
* IPv6: (none)
* IPv4: 10.107.183.231
*   Trying 10.107.183.231:8000...
* Connected to app-backend (10.107.183.231) port 8000
> GET / HTTP/1.1
> Host: app-backend:8000
> User-Agent: curl/8.5.0
> Accept: */*
> 
< HTTP/1.1 404 Not Found
< date: Mon, 14 Apr 2025 14:20:05 GMT
< server: uvicorn
< content-length: 22
< content-type: application/js


File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 308, in _do_get
    return self._create_connection()
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/root/.cache/pypoetry/virtualenvs/atlantis-fastapi-cCrPfAjT-py3.10/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()

FROM node:20-alpine AS builder
WORKDIR /app
COPY package.json package-lock.json ./
RUN npm install
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist/ /usr/share/nginx/html
EXPOSE 80

Back-off restarting failed container frontend in pod app-frontend-5795c45db8-5z9pf_atlantis(08728b66-b7b6-4c90-a214-f8aa3bef7786)

WebSocket connection to 'ws://atlantis.com/?token=Nn8hhDXRC70m' failed: 
createConnection @ client:756Understand this errorAI
client:769 WebSocket connection to 'ws://localhost:5173/?token=Nn8hhDXRC70m' failed: 
createConnection @ client:769Understand this errorAI
client:784 [vite] failed to connect to websocket.
your current setup:
  (browser) atlantis.com/ <--[HTTP]--> localhost:5173/ (server)
  (browser) atlantis.com:/ <--[WebSocket (failing)]--> localhost:5173/ (server)
Check out your Vite / network configuration and 

minikube tunnel
helm upgrade -f values.yaml ingress-nginx ingress-nginx/ingress-nginx --namespace ingress-nginx


0/1 nodes are available: persistentvolumeclaim "app-postgres-pvc" not found. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.


FROM python:3.10
WORKDIR /app
COPY pyproject.toml poetry.lock .
# RUN apt-get update && apt-get upgrade -y
# RUN  curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/
#get-poetry.py | python -
#RUN bash -c "source $HOME/.poetry/env"
RUN pip install poetry
RUN poetry install --no-root
COPY . .
COPY entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh
ENTRYPOINT ["/app/entrypoint.sh"]



Back-off restarting failed container backend in pod app-backend-85767b5f7b-rl8cr_atlantis(ebd805d1-9622-4858-a013-b36edb3cfd66)
6
83s
Container image "atl-back:latest" already present on machine
4
87s
Created container: backend
4
87s
Error: failed to start container "backend": Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: exec: "entrypoint.sh": executable file not found in $PATH: unknown
4

OCI runtime exec failed: exec failed: unable to start container process: exec: "/bin/bash": stat /bin/bash: no such file or directory: unknown


ERROR [internal] load metadata for docker.io/library/build:latest                                                          0.7s
 => CANCELED [internal] load metadata for docker.io/library/nginx:alpine                                                       0.7s
------
 > [internal] load metadata for docker.io/library/build:latest:
------

 1 warning found (use docker --debug to expand):
 - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 1)
Dockerfile:9
--------------------
   7 |     
   8 |     FROM nginx:alpine
   9 | >>> COPY --from=build /app/build /usr/share/nginx/html
  10 |     EXPOSE 80
  11 |     CMD ["nginx", "-g", "daemon off;" ]
--------------------
ERROR: failed to solve: build: failed to resolve source metadata for docker.io/library/build:latest: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed (did you mean builder?)



failed to solve: build: failed to resolve source metadata for docker.io/library/build:latest: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed (did you mean builder?)


failed to solve: process "/bin/sh -c npm install" did not complete successfully: exit code: 127

nodes are available: persistentvolumeclaim "app-postgres-pvc" not found. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.

Unexpected error obtaining ingress-nginx pod: unable to get POD information (missing POD_NAME or POD_NAMESPACE environment variable


No permissions to list and get Ingress Classes: ingressclasses.networking.k8s.io is forbidden: User "system:serviceaccount:ingress-nginx:nginx-ingress-serviceaccount" cannot list resource "ingressclasses" in API group "networking.k8s.io" at the cluster scope, IngressClass feature will be disabled

apiVersion: v1
kind: Service
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx
spec:
  type: NodePort  # Или LoadBalancer для облачных провайдеров
  ports:
    - name: http
      port: 80
      targetPort: http
      protocol: TCP
    - name: https
      port: 443
      targetPort: https
      protocol: TCP
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx


rules:
  # Правила доступа для Ingress-контроллера
  - apiGroups: [""]
    resources: ["configmaps", "endpoints", "nodes", "pods", "secrets"]
    verbs: ["list", "watch"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["networking.k8s.io"]
    resources: ["ingresses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nginx-ingress-clusterrole-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nginx-ingress-clusterrole
subjects:
  - kind: ServiceAccount
    name: nginx-ingress-serviceaccount
    namespace: ingress-nginx

Error: INSTALLATION FAILED: 2 errors occurred:
	* Deployment in version "v1" cannot be handled as a Deployment: json: cannot unmarshal object into Go struct field Container.spec.template.spec.containers.ports of type []v1.ContainerPort
	* Ingress.networking.k8s.io "app-ingress-rule" is invalid: spec.rules[0].host: Invalid value: "localhost:5173": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')


kubectl exec -it postgres-pod -- bash -c "echo \"listen_addresses = '*'\" >> /var/lib/postgresql/data/postgresql.conf"

bash -c "echo 'host all all 0.0.0.0/0 trust' >> /var/lib/postgresql/data/pg_hba.conf"

telnet: can't connect to remote host (10.109.8.131): Connection refused


until nc -z -v -w30 {{ .Release.Name }}-postgres 5432; do

* Job in version "v1" cannot be handled as a Job: json: cannot unmarshal object into Go struct field PodSpec.spec.template.spec.initContainers of type []v1.Container


Error: INSTALLATION FAILED: unable to build kubernetes objects from release manifest: resource mapping not found for name: "app-migrate" namespace: "" from "": no matches for kind "job" in version "batch/v1beta1"
ensure CRDs are installed first


* Deployment.apps "app-postgres" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: "postgres-storage"


* Deployment in version "v1" cannot be handled as a Deployment: json: cannot unmarshal object into Go struct field PodSpec.spec.template.spec.containers of type []v1.Container
	* job in version "v1" cannot be handled as a Job: no kind "job" is registered for version "batch/v1" in scheme "pkg/api/legacyscheme/scheme.go:30"

Failed to pull image "frontend": Error response from daemon: pull access denied for frontend, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
db:
    image: postgres:13
    container_name: postgres 
    environment:
      POSTGRES_USER: myuser            
      POSTGRES_PASSWORD: mypassword    
      POSTGRES_DB: mydatabase         
    volumes:
      - ./postgres_data:/var/lib/postgresql/data  
    ports:
      - "5433:5432"  
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "myuser"]
      interval: 10s
      timeout: 5s
      retries: 5

resource "aws_launch_configuration" "ecs_lc" {
  name          = "ecs-launch-config"
  image_id      = "ami-0c55b159cbfafe1f0" # Замени на актуальный ECS-AMI
  instance_type = "t2.micro"
  security_groups = [aws_security_group.ecs_sg.id]
  user_data = <<EOF
#!/bin/bash
echo "ECS_CLUSTER=${aws_ecs_cluster.ecs_cluster.name}" >> /etc/ecs/ecs.config
EOF
  lifecycle {
    create_before_destroy = true
  }
}

resource "aws_autoscaling_group" "ecs_asg" {
  desired_capacity     = 1
  max_size            = 1
  min_size            = 1
  vpc_zone_identifier = [aws_subnet.subnet.id]
  launch_configuration = aws_launch_configuration.ecs_lc.id
}

resource "aws_ecs_task_definition" "ecs_task" {
  family                   = "example-task"
  network_mode             = "bridge"
  requires_compatibilities = ["EC2"]
  container_definitions = jsonencode([
    {
      name      = "example-container"
      image     = "nginx:latest"
      memory    = 256
      cpu       = 128
      essential = true
      portMappings = [
        {
          containerPort = 80
          hostPort      = 80
        }
      ]
    }
  ])
}

resource "aws_ecs_service" "ecs_service" {
  name            = "example-service"
  cluster         = aws_ecs_cluster.ecs_cluster.id
  task_definition = aws_ecs_task_definition.ecs_task.arn
  desired_count   = 1
  launch_type     = "EC2"
}


ERROR: failed to solve: failed to compute cache key: failed to calculate checksum of ref 1facf49a-7004-4268-a80a-1adc292b6635::94oiepgi8dvdnr9inkp1elvez: "/entrypoint": not found

GPT PMBR size mismatch (16777215 != 25165823) will be corrected by write.
The backup GPT table is not on the end of the device. This problem will be corrected by write.
This disk is currently in use - repartitioning is probably a bad idea.
It's recommended to umount all file systems, and swapoff all swap
partitions on this disk.


sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "db" to address: Temporary failure in name resolution

[build 6/6] RUN npm run build:
0.317 
0.317 > atlantis-typescript@0.0.0 build
0.317 > tsc -b && vite build
0.317 
6.493 src/components/form/Form.tsx(57,44): error TS2339: Property 'data' does not exist on type '{}'.
6.494 src/components/sideBar/SideBar.tsx(1,9): error TS6133: 'Divider' is declared but its value is never read.
6.495 src/components/sideBar/SideBar.tsx(7,1): error TS6133: 'React' is declared but its value is never read.
6.495 src/features/clients/components/ClientDeleteModal.tsx(16,37): error TS7031: Binding element 'onConfirm' implicitly has an 'any' type.
6.495 src/features/clients/components/ClientDeleteModal.tsx(16,48): error TS7031: Binding element 'onCancel' implicitly has an 'any' type.
6.495 src/features/clients/components/ClientsForm.tsx(5,1): error TS6133: 'dayjs' is declared but its value is never read.
6.495 src/features/clients/components/ClientsForm.tsx(74,33): error TS7006: Parameter 'values' implicitly has an 'any' type.
6.497 src/features/clients/components/ClientsForm.tsx(74,41): error TS7031: Binding element 'resetForm' implicitly has an 'any' type.
6.497 src/features/clients/components/ClientsForm.tsx(92,36): error TS2339: Property 'data' does not exist on type '{}'.
6.498 src/features/clients/tables/clientsColumns.ts(3,47): error TS2304: Cannot find name 'rows'.
6.498 src/layouts/Clients.tsx(1,22): error TS6133: 'Divider' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(1,43): error TS6133: 'List' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(1,49): error TS6133: 'ListItem' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(1,59): error TS6133: 'ListItemIcon' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(1,80): error TS6133: 'Typography' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(13,1): error TS6133: 'Checkbox' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(14,1): error TS6133: 'WarningSpan' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(15,1): error TS6133: 'CircleIcon' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(17,1): error TS6133: 'IClientGet' is declared but its value is never read.
6.498 src/layouts/Clients.tsx(43,35): error TS7006: Parameter 'params' implicitly has an 'any' type.
6.498 src/layouts/Clients.tsx(55,13): error TS2304: Cannot find name 'setIsAbleToDelete'.
6.498 src/layouts/Clients.tsx(64,33): error TS7006: Parameter 'e' implicitly has an 'any' type.
6.498 src/layouts/Clients.tsx(76,33): error TS7006: Parameter 'params' implicitly has an 'any' type.
6.498 src/layouts/Clients.tsx(89,9): error TS2304: Cannot find name 'setIsAbleToDelete'.
6.498 src/layouts/Clients.tsx(123,29): error TS2322: Type 'GridRowId' is not assignable to type 'number'.
6.498   Type 'string' is not assignable to type 'number'.
6.500 src/layouts/HomeLayout.tsx(5,9): error TS6133: 'Navigate' is declared but its value is never read.
6.500 src/layouts/HomeLayout.tsx(20,11): error TS6198: All destructured elements are unused.
6.500 src/pages/home.tsx(20,110): error TS2339: Property 'data' does not exist on type 'FetchBaseQueryError | SerializedError'.
6.500   Property 'data' does not exist on type 'SerializedError'.
6.500 src/store/apis/clientsApi.ts(2,35): error TS2307: Cannot find module '../../models/client.ts' or its corresponding type declarations.
------
Dockerfile:6
--------------------
   4 |     RUN npm install
   5 |     COPY . .
   6 | >>> RUN npm run build
   7 |     
   8 |     FROM nginx:alpine
--------------------
ERROR: failed to solve: process "/bin/sh -c npm run build" did not complete successfully: exit code: 2
